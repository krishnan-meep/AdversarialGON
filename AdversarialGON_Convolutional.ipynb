{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From  https://github.com/cwkx/GON\n",
    "# requirements\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# colab requirements\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data\n",
    "img_size = 32\n",
    "n_channels = 3\n",
    "img_coords = 2\n",
    "\n",
    "# training info\n",
    "lr = 1e-4\n",
    "batch_size = 64\n",
    "nz = 128\n",
    "ngf = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, sampler=None, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the GON network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ELU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ELU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ELU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, n_channels, 4, 2, 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "        \n",
    "class Res_Block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super(Res_Block, self).__init__()\n",
    "    self.C1 = nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, 3, 1, 1))\n",
    "    self.C2 = nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, 4, 2, 1))\n",
    "    self.CS = nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, 4, 2, 1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x_i = self.CS(x)\n",
    "    x = nn.functional.leaky_relu(self.C1(x))\n",
    "    x = nn.functional.leaky_relu(x_i + self.C2(x))\n",
    "    return x\n",
    "\n",
    "class Disc(nn.Module):\n",
    "  def __init__(self, img_size):\n",
    "    super(Disc, self).__init__()\n",
    "    self.h, self.w = img_size//8, img_size//8\n",
    "    self.C1 = nn.utils.spectral_norm(nn.Conv2d(3, 32, 4, 2, 1))\n",
    "    self.C2 = nn.utils.spectral_norm(nn.Conv2d(32, 64, 4, 2, 1))\n",
    "    self.C3 = nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1))\n",
    "    self.C4 = nn.utils.spectral_norm(nn.Conv2d(128, 128, 3, 1, 1))\n",
    "\n",
    "    self.R1 = Res_Block(3, 32)\n",
    "    self.R2 = Res_Block(32, 64)\n",
    "    self.R3 = Res_Block(64, 128)\n",
    "    self.D1 = nn.utils.spectral_norm(nn.Linear(128*self.h*self.w, 1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    #x = nn.functional.leaky_relu(self.C1(x))\n",
    "    #x = nn.functional.leaky_relu(self.C2(x))\n",
    "    #x = nn.functional.leaky_relu(self.C3(x))\n",
    "    x = self.R3(self.R2(self.R1(x)))\n",
    "    x = nn.functional.leaky_relu(self.C4(x))\n",
    "    x = x.reshape(x.size(0), 128*self.h*self.w)\n",
    "    return self.D1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "def slerp(a, b, t):\n",
    "    omega = torch.acos((a/torch.norm(a, dim=1, keepdim=True)*b/torch.norm(b, dim=1, keepdim=True)).sum(1)).unsqueeze(1)\n",
    "    res = (torch.sin((1.0-t)*omega)/torch.sin(omega))*a + (torch.sin(t*omega)/torch.sin(omega)) * b\n",
    "    return res\n",
    "\n",
    "def slerp_batch(model, z):\n",
    "    lz = z.data.clone().squeeze(-1).squeeze(-1)\n",
    "    col_size = int(np.sqrt(z.size(0)))\n",
    "    src_z = lz.data[:col_size].repeat(col_size,1)\n",
    "    z1, z2 = lz.data.split(lz.shape[0]//2)\n",
    "    tgt_z = torch.cat([z2, z1])\n",
    "    tgt_z = tgt_z[:col_size].repeat(col_size,1)\n",
    "    t = torch.linspace(0,1,col_size).unsqueeze(1).repeat(1,col_size).contiguous().view(batch_size,1).contiguous().to(device)\n",
    "    z_slerp = slerp(src_z, tgt_z, t)\n",
    "    g_slerp = model(z_slerp.unsqueeze(-1).unsqueeze(-1))\n",
    "    return g_slerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Generator().to(device)\n",
    "D = Disc(img_size).to(device)\n",
    "\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(lr=lr, params=F.parameters())\n",
    "optimizerD = torch.optim.Adam(lr = 0.0005, params = D.parameters(), betas = (0.0, 0.99))\n",
    "print(f'> Number of G parameters {len(torch.nn.utils.parameters_to_vector(F.parameters()))}')\n",
    "print(f'> Number of D parameters {len(torch.nn.utils.parameters_to_vector(D.parameters()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(cycle(train_loader))\n",
    "iterations = 10000 + 1\n",
    "recent_zs = []\n",
    "\n",
    "for step in range(iterations):\n",
    "    # sample a batch of data\n",
    "    x, t = next(train_iterator)\n",
    "    x, t = x.to(device), t.to(device)\n",
    "    real_label, fake_label = torch.ones(x.size(0), 1).to(device), torch.zeros(x.size(0), 1).to(device)\n",
    "\n",
    "    # compute the gradients of the inner loss with respect to zeros (gradient origin)\n",
    "    z = torch.zeros(batch_size, nz, 1, 1).to(device).requires_grad_()\n",
    "    g = F(z)\n",
    "    L_inner = ((g - x)**2).sum(1).mean()\n",
    "    grad = torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
    "    z = (-grad)\n",
    "\n",
    "    # now with z as our new latent points, optimise the data fitting loss\n",
    "    g = F(z)\n",
    "\n",
    "    fake_output = D(g)\n",
    "    real_output = D(x)\n",
    "    errG = torch.mean(((real_output - torch.mean(fake_output)) - fake_label)**2) + torch.mean(((fake_output - torch.mean(real_output)) - real_label)**2)\n",
    "    errG /= 2\n",
    "\n",
    "    L_outer = errG + 10*((g - x)**2).sum(1).mean()\n",
    "    optim.zero_grad()\n",
    "    L_outer.backward()\n",
    "    optim.step()\n",
    "\n",
    "    recent_zs.append(z.detach())\n",
    "    recent_zs = recent_zs[-100:]\n",
    "    \n",
    "    #Discomator ####################################################################################################\n",
    "    D.zero_grad()\n",
    "    real_images = x\n",
    "    sample = g.detach()\n",
    "\n",
    "    real_output = D(real_images)\n",
    "    fake_output = D(sample)\n",
    "    \n",
    "    errD_real = torch.mean(((real_output - torch.mean(fake_output)) - real_label)**2) \n",
    "    errD_fake = torch.mean(((fake_output - torch.mean(real_output)) - fake_label)**2)\n",
    "    errD = (errD_fake + errD_real)/2\n",
    "    errD.backward()\n",
    "    optimizerD.step()\n",
    "\n",
    "    if step % 50 == 0 and step > 0:\n",
    "        print(f\"Step: {step}   Loss: {L_outer.item():.3f} ({errG.item():.3f}) DLoss: {errD.item():.3f}\")\n",
    "    if step % 250 == 0 and step > 0:\n",
    "        clear_output()\n",
    "        print(f\"Step: {step}   Loss: {L_outer.item():.3f} ({errG.item():.3f}) DLoss: {errD.item():.3f}\")\n",
    "\n",
    "        # plot reconstructions and interpolations\n",
    "        recons = torchvision.utils.make_grid(torch.clamp(g, 0, 1)[:16], nrow=8)\n",
    "        slerps = torchvision.utils.make_grid(torch.clamp(slerp_batch(F, z.data), 0, 1), nrow=8)\n",
    "        print(recons.shape)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.title('Reconstructions')\n",
    "        plt.imshow(recons.permute(1,2,0).cpu().data.numpy())\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.title('Spherical Interpolations')\n",
    "        plt.imshow(slerps.permute(1,2,0).cpu().data.numpy())\n",
    "        plt.show()\n",
    "        sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
